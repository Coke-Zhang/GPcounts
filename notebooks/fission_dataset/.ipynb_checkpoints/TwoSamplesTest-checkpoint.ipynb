{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalise gene expression data and run two samples test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuha BinTayyash, 2020\n",
    "\n",
    "This notebook shows how to run [DESeq2](https://bioconductor.org/packages/release/bioc/html/DESeq2.html)  R package to normalise [fission](https://bioconductor.org/packages/release/data/experiment/html/fission.html) gene expression data then run GPcounts two samples test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load [fission dataset](https://bioconductor.org/packages/3.11/data/experiment/html/fission.html) and normalise it using DESeq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: SummarizedExperiment\n",
      "Loading required package: GenomicRanges\n",
      "Loading required package: stats4\n",
      "Loading required package: BiocGenerics\n",
      "Loading required package: parallel\n",
      "\n",
      "Attaching package: ‘BiocGenerics’\n",
      "\n",
      "The following objects are masked from ‘package:parallel’:\n",
      "\n",
      "    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,\n",
      "    clusterExport, clusterMap, parApply, parCapply, parLapply,\n",
      "    parLapplyLB, parRapply, parSapply, parSapplyLB\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    IQR, mad, sd, var, xtabs\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    anyDuplicated, append, as.data.frame, basename, cbind, colnames,\n",
      "    dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep,\n",
      "    grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget,\n",
      "    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,\n",
      "    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,\n",
      "    union, unique, unsplit, which, which.max, which.min\n",
      "\n",
      "Loading required package: S4Vectors\n",
      "\n",
      "Attaching package: ‘S4Vectors’\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    expand.grid\n",
      "\n",
      "Loading required package: IRanges\n",
      "Loading required package: GenomeInfoDb\n",
      "Loading required package: Biobase\n",
      "Welcome to Bioconductor\n",
      "\n",
      "    Vignettes contain introductory material; view with\n",
      "    'browseVignettes()'. To cite Bioconductor, see\n",
      "    'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n",
      "\n",
      "Loading required package: DelayedArray\n",
      "Loading required package: matrixStats\n",
      "\n",
      "Attaching package: ‘matrixStats’\n",
      "\n",
      "The following objects are masked from ‘package:Biobase’:\n",
      "\n",
      "    anyMissing, rowMedians\n",
      "\n",
      "Loading required package: BiocParallel\n",
      "\n",
      "Attaching package: ‘DelayedArray’\n",
      "\n",
      "The following objects are masked from ‘package:matrixStats’:\n",
      "\n",
      "    colMaxs, colMins, colRanges, rowMaxs, rowMins, rowRanges\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    aperm, apply, rowsum\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(\"fission\")\n",
    "data(\"fission\")\n",
    "counts <- SummarizedExperiment::assay(fission)\n",
    "col_data <- fission@colData\n",
    "write.csv(counts, file = \"fission_counts.csv\")\n",
    "write.csv(col_data, file = \"fission_col_data.csv\")\n",
    "\n",
    "wt_counts <- counts[,1:18]\n",
    "wt_col_data <- col_data[1:18,]\n",
    "write.csv(wt_counts, file = \"wt_counts.csv\")\n",
    "write.csv(wt_col_data, file = \"wt_col_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESeq2 two samples test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using pre-existing size factors\n",
      "estimating dispersions\n",
      "gene-wise dispersion estimates\n",
      "mean-dispersion relationship\n",
      "final dispersion estimates\n",
      "fitting model and testing\n"
     ]
    }
   ],
   "source": [
    "library(\"DESeq2\")\n",
    "dds <- DESeqDataSetFromMatrix(countData = counts,\n",
    "                              colData = col_data,\n",
    "                              design = ~ strain + minute + strain:minute)\n",
    "\n",
    "dds <- estimateSizeFactors(dds)\n",
    "normalized_counts<-counts(dds, normalized=TRUE)\n",
    "write.csv(normalized_counts, file = \"wt_normalized_counts.csv\")\n",
    "\n",
    "dds <- DESeq(dds, test=\"LRT\", reduced = ~ strain + minute)\n",
    "res <- results(dds)\n",
    "write.csv(as.data.frame(res),file=\"fission_DESeq2_tst.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using pre-existing size factors\n",
      "estimating dispersions\n",
      "gene-wise dispersion estimates\n",
      "mean-dispersion relationship\n",
      "final dispersion estimates\n",
      "fitting model and testing\n"
     ]
    }
   ],
   "source": [
    "dds <- DESeqDataSetFromMatrix(countData = wt_counts,\n",
    "                              colData = wt_col_data,\n",
    "                              design = ~  minute)\n",
    "\n",
    "dds <- estimateSizeFactors(dds)\n",
    "normalized_counts<-counts(dds, normalized=TRUE)\n",
    "write.csv(normalized_counts, file = \"wt_normalized_counts.csv\")\n",
    "\n",
    "dds <- DESeq(dds, test=\"LRT\", reduced = ~ 1)\n",
    "res <- results(dds)\n",
    "write.csv(as.data.frame(res),file=\"fission_DESeq2_ost.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change R kernel to Python kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.read_csv('fission_counts.csv',index_col=[0])\n",
    "time_points = pd.read_csv('fission_col_data.csv',index_col=[0])\n",
    "time_points = time_points[['minute']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM1368273</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1368274</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1368275</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1368276</th>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1368277</th>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              minute\n",
       "GSM1368273  0.000000\n",
       "GSM1368274  0.000000\n",
       "GSM1368275  0.000000\n",
       "GSM1368276  0.083333\n",
       "GSM1368277  0.083333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = time_points\n",
    "X = (X  - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)) \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"scaled_time_points.csv\")\n",
    "X.iloc[0:18,:].to_csv(\"scaled_one_ts_time_points.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the first gene in fission gene expression data using GPcounts -- Two samples test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPcounts.GPcounts_Module import Fit_GPcounts\n",
    "likelihood = 'Negative_binomial' \n",
    "genes_name = ['']\n",
    "gp_counts = Fit_GPcounts(X,Y.loc[genes_name]) \n",
    "log_likelihood_ratio = gp_counts.Two_samples_test(likelihood)\n",
    "log_likelihood_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def plot(likelihood,xtest,model,mean,var,count):\n",
    "         \n",
    "    plt.ylabel('Gene Expression', fontsize=16)\n",
    "    plt.xlabel('Times', fontsize=16)\n",
    "    \n",
    "    if count == 1 or count == 2:\n",
    "        c = 'blue'\n",
    "\n",
    "    else:\n",
    "        c = 'salmon'\n",
    "    \n",
    "    \n",
    "    if likelihood == 'Gaussian':\n",
    "        plt.fill_between(xtest[:,0],\n",
    "                            mean[:,0] - 1*np.sqrt(var[:,0]),\n",
    "                            mean[:,0] + 1*np.sqrt(var[:,0]), alpha=0.2) # one standard deviation\n",
    "        plt.fill_between(xtest[:,0],\n",
    "                            mean[:,0] - 2*np.sqrt(var[:,0]),\n",
    "                            mean[:,0] + 2*np.sqrt(var[:,0]),color='light'+c, alpha=0.2)# two standard deviation\n",
    "    else:\n",
    "        \n",
    "        lowess = sm.nonparametric.lowess\n",
    "        \n",
    "        # one standard deviation 68%\n",
    "        percentile_16 = lowess(np.percentile(var, 16, axis=0),xtest[:,0],frac=1./5, return_sorted=False)\n",
    "        percentile_84 = lowess(np.percentile(var, 84, axis=0),xtest[:,0],frac=1./5, return_sorted=False)\n",
    "        plt.fill_between(xtest[:,0],percentile_16,percentile_84,alpha = 0.2)\n",
    "        \n",
    "        # two standard deviation 95%\n",
    "        percentile_5 = lowess(np.percentile(var, 5, axis=0),xtest[:,0],frac=1./5, return_sorted=False)\n",
    "        percentile_95 = lowess(np.percentile(var,95, axis=0),xtest[:,0],frac=1./5, return_sorted=False)\n",
    "        plt.fill_between(xtest[:,0],percentile_5,percentile_95,color='light'+c,alpha = 0.2)\n",
    "        \n",
    "    plt.plot(xtest, mean, lw=2) \n",
    "    plt.scatter(model.data[0],model.data[1], s=10, color= c, alpha=0.6) #data\n",
    "\n",
    "    if count == 1 or count ==3:\n",
    "        plt.show()\n",
    "        \n",
    "indexes = log_likelihood_ratio.index.values # list of genes to be plotted \n",
    "test = 'Two_samples_test' # name of the test\n",
    "xtest = np.linspace(np.min(X.values),np.max(X.values),100)[:,None] # points to make prediction\n",
    "sample = True # sample or/and load model \n",
    "likelihood = 'Negative_binomial'\n",
    "params = gp_counts.load_and_sample_models(indexes,test,xtest,likelihood,sample)\n",
    "\n",
    "for i in range(len(indexes)):\n",
    "    fig = plt.figure()\n",
    "    print(indexes[i])\n",
    "    count = 1\n",
    "    for models,mean,var in zip(params['models'][i],params['means'][i],params['vars'][i]):\n",
    "        mean = np.array(mean)\n",
    "        var = np.array(var)\n",
    "        plot(likelihood,xtest,models,mean,var,count)\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = 'Gaussian'\n",
    "log_likelihood_ratio = gp_counts.Two_samples_test(likelihood)\n",
    "log_likelihood_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = gp_counts.load_and_sample_models(indexes,test,xtest,likelihood,sample)\n",
    "\n",
    "for i in range(len(indexes)):\n",
    "    fig = plt.figure()\n",
    "    print(indexes[i])\n",
    "    count = 1\n",
    "    for models,mean,var in zip(params['models'][i],params['means'][i],params['vars'][i]):\n",
    "        mean = np.array(mean)\n",
    "        var = np.array(var)\n",
    "        plot(likelihood,xtest,models,mean,var,count)\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv] *",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
